import CoreML
import CreateML
import CreateMLComponents
import CSInterface
import Foundation

public final class MultiLabelClassificationTrainer: ScreeningTrainerProtocol {
    public typealias TrainingResultType = MultiLabelTrainingResult

    private struct ManifestEntry: Decodable {
        let filename: String
        let annotations: [String]
    }

    public var outputDirPath: String {
        var dir = URL(fileURLWithPath: #filePath)
        dir.deleteLastPathComponent()
        dir.deleteLastPathComponent()
        return dir.appendingPathComponent("OutputModels").path
    }

    public var classificationMethod: String { "MultiLabel" }
    public var manifestFileName: String { "multilabel_cat_annotations.json" }

    public var resourcesDirectoryPath: String {
        var dir = URL(fileURLWithPath: #filePath)
        dir.deleteLastPathComponent()
        dir.deleteLastPathComponent()
        return dir.appending(path: "Resources").path
    }

    /// ã‚½ãƒ•ãƒˆãªåˆ†å¸ƒã‚’ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«ã«å¤‰æ›ã™ã‚‹ãŸã‚ã®ä¿¡é ¼åº¦ã®é–¾å€¤
    private let predictionThreshold: Float = 0.5

    public init() {}

    public func train(
        author: String,
        modelName: String,
        version: String,
        maxIterations: Int
    ) async -> MultiLabelTrainingResult? {
        let outputDir: URL
        do {
            outputDir = try createOutputDirectory(
                modelName: modelName,
                version: version
            )
        } catch {
            print("âŒ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ â€“ \(error.localizedDescription)")
            return nil
        }

        let resourcesDir = URL(fileURLWithPath: resourcesDirectoryPath)
        let manifestURL = resourcesDir.appending(path: manifestFileName)

        guard
            let manifestData = try? Data(contentsOf: manifestURL),
            let entries = try? JSONDecoder().decode([ManifestEntry].self, from: manifestData),
            !entries.isEmpty
        else {
            print("âŒ ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã®èª­ã¿å–ã‚Šã¾ãŸã¯ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: \(manifestURL.path)")
            return nil
        }

        let annotatedFeatures: [AnnotatedFeature<URL, Set<String>>] = entries.compactMap { entry in
            let fileURL = resourcesDir.appending(path: entry.filename)
            return AnnotatedFeature(feature: fileURL, annotation: Set(entry.annotations))
        }

        let labels = Set(annotatedFeatures.flatMap(\.annotation)).sorted()
        guard !labels.isEmpty else {
            print("âŒ ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã§ãƒ©ãƒ™ãƒ«ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            return nil
        }
        print("ğŸ“š ãƒ©ãƒ™ãƒ«: \(labels.joined(separator: ", "))")

        let classifier = FullyConnectedNetworkMultiLabelClassifier<Float, String>(
            labels: Set(labels)
        )
        let featureExtractor = ImageFeaturePrint(revision: 1)
        let pipeline = featureExtractor.appending(classifier)

        let reader = ImageReader()
        let (trainSet, validationSet) = annotatedFeatures.randomSplit(by: 0.8)
        guard
            let trainingFeatures = try? await reader.applied(to: trainSet),
            let validationFeatures = try? await reader.applied(to: validationSet)
        else {
            print("âŒ ç”»åƒãƒªãƒ¼ãƒ€ãƒ¼ã®é©ç”¨ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return nil
        }

        print("â³ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ â€“ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: \(trainSet.count) / æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: \(validationSet.count)")

        let t0 = Date()
        let fittedPipeline: ComposedTransformer<
            ImageFeaturePrint,
            FullyConnectedNetworkMultiLabelClassifier<Float, String>.Transformer
        >
        do {
            fittedPipeline = try await pipeline.fitted(to: trainingFeatures, validateOn: validationFeatures)
        } catch {
            print("âŒ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ â€“ \(error.localizedDescription)")
            return nil
        }
        let trainingTime = Date().timeIntervalSince(t0)
        print("ğŸ‰ \(String(format: "%.2f", trainingTime)) ç§’ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ")

        var perLabelMetricsResults: [String: (tp: Int, fp: Int, fn: Int)] = [:]
        for label in labels {
            perLabelMetricsResults[label] = (tp: 0, fp: 0, fn: 0)
        }

        if let validationPredictions = try? await fittedPipeline.applied(to: validationFeatures) {
            print("ğŸ§ª æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã‚’å–å¾—ã—ã¾ã—ãŸã€‚ã‚µãƒ³ãƒ—ãƒ«æ•°: \(validationPredictions.count)")
            for i in 0..<validationSet.count {
                let trueAnnotations = validationSet[i].annotation
                let annotatedPrediction = validationPredictions[i]
                let actualDistribution = annotatedPrediction.feature
                
                var predictedLabels = Set<String>()
                for labelInDataset in labels {
                    if let score = actualDistribution[labelInDataset], score >= predictionThreshold {
                        predictedLabels.insert(labelInDataset)
                    }
                }

                for label in labels {
                    let trulyHasLabel = trueAnnotations.contains(label)
                    let predictedHasLabel = predictedLabels.contains(label)

                    if trulyHasLabel && predictedHasLabel {
                        perLabelMetricsResults[label]?.tp += 1
                    } else if !trulyHasLabel && predictedHasLabel {
                        perLabelMetricsResults[label]?.fp += 1
                    } else if trulyHasLabel && !predictedHasLabel {
                        perLabelMetricsResults[label]?.fn += 1
                    }
                }
            }
        } else {
            print("âš ï¸ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ©ãƒ™ãƒ«åˆ¥æŒ‡æ¨™ã¯è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")
        }
        
        struct PerLabelCalculatedMetrics {
            let label: String
            let recall: Double
            let precision: Double
        }
        var calculatedMetricsForDescription: [PerLabelCalculatedMetrics] = []

        for label in labels.sorted() {
            if let counts = perLabelMetricsResults[label] {
                let recall = (counts.tp + counts.fn == 0) ? 0.0 : Double(counts.tp) / Double(counts.tp + counts.fn)
                let precision = (counts.tp + counts.fp == 0) ? 0.0 : Double(counts.tp) / Double(counts.tp + counts.fp)
                calculatedMetricsForDescription.append(PerLabelCalculatedMetrics(label: label, recall: recall, precision: precision))
                print("    ğŸ”– ãƒ©ãƒ™ãƒ«: \(label) - å†ç¾ç‡: \(String(format: "%.2f", recall * 100))%, é©åˆç‡: \(String(format: "%.2f", precision * 100))% (TP: \(counts.tp), FP: \(counts.fp), FN: \(counts.fn))")
            }
        }
        // ---- END: Calculate Per-Label Recall and Precision ----

        // .mlmodel ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«å«ã‚ã‚‹ shortDescription ã‚’å‹•çš„ã«ç”Ÿæˆ
        var descriptionParts: [String] = []

        // 1. ãƒ©ãƒ™ãƒ«æƒ…å ±
        if !labels.isEmpty {
            descriptionParts.append("ãƒ©ãƒ™ãƒ«: " + labels.joined(separator: ", "))
        } else {
            descriptionParts.append("ãƒ©ãƒ™ãƒ«æƒ…å ±ãªã—")
        }

        // 2. æœ€å¤§åå¾©å›æ•°
        descriptionParts.append("æœ€å¤§åå¾©å›æ•° (æŒ‡å®šå€¤): \(maxIterations)å›")

        // 3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±
        descriptionParts.append(String(format: "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: %dæš, æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿æ•°: %dæš", trainSet.count, validationSet.count))

        // ---- START: Add Per-Label Metrics to Description ----
        if !calculatedMetricsForDescription.isEmpty {
            descriptionParts.append("ãƒ©ãƒ™ãƒ«åˆ¥æ¤œè¨¼æŒ‡æ¨™ (ã—ãã„å€¤: \(predictionThreshold)):")
            for metrics in calculatedMetricsForDescription {
                let metricsString = String(format: "    %@: å†ç¾ç‡ %.1f%%, é©åˆç‡ %.1f%%",
                                           metrics.label,
                                           metrics.recall * 100,
                                           metrics.precision * 100)
                descriptionParts.append(metricsString)
            }
        } else {
            descriptionParts.append("ãƒ©ãƒ™ãƒ«åˆ¥æ¤œè¨¼æŒ‡æ¨™: è¨ˆç®—ã‚¹ã‚­ãƒƒãƒ—ã¾ãŸã¯å¤±æ•—")
        }
        // ---- END: Add Per-Label Metrics to Description ----

        // 4. æ¤œè¨¼æ–¹æ³•
        descriptionParts.append("(æ¤œè¨¼: 80/20ãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²)")

        let modelShortDescription = descriptionParts.joined(separator: "\n")

        let modelMetadata = ModelMetadata(
            description: modelShortDescription,
            version: version,
            author: author
        )

        let modelURL = outputDir.appendingPathComponent("\(modelName)_\(classificationMethod)_\(version).mlmodel")
        do {
            try fittedPipeline.export(to: modelURL, metadata: modelMetadata)
            print("âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ \(modelURL.path) ã«ä¿å­˜ã—ã¾ã—ãŸ")
        } catch {
            print("âŒ ãƒ¢ãƒ‡ãƒ«ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ â€“ \(error.localizedDescription)")
            return nil
        }

        let finalMeanAP: Double? = nil // mAPã¯ç¾æ™‚ç‚¹ã§ã¯è¨ˆç®—ã—ãªã„
        let finalPerLabelSummary = calculatedMetricsForDescription.isEmpty ? "è©•ä¾¡ã‚¹ã‚­ãƒƒãƒ—ã¾ãŸã¯å¤±æ•—" : "ãƒ©ãƒ™ãƒ«åˆ¥ å†ç¾ç‡/é©åˆç‡ã¯ãƒ¢ãƒ‡ãƒ«Descriptionå‚ç…§"
        var avgRecallDouble: Double? = nil
        var avgPrecisionDouble: Double? = nil

        if !calculatedMetricsForDescription.isEmpty {
            avgRecallDouble = calculatedMetricsForDescription.map { $0.recall }.reduce(0, +) / Double(calculatedMetricsForDescription.count)
            avgPrecisionDouble = calculatedMetricsForDescription.map { $0.precision }.reduce(0, +) / Double(calculatedMetricsForDescription.count)
        }

        return MultiLabelTrainingResult(
            modelName: modelName,
            trainingDurationInSeconds: trainingTime,
            modelOutputPath: modelURL.path,
            trainingDataPath: manifestURL.path,
            classLabels: labels,
            maxIterations: maxIterations,
            meanAveragePrecision: finalMeanAP,
            perLabelMetricsSummary: finalPerLabelSummary,
            averageRecallAcrossLabels: avgRecallDouble,
            averagePrecisionAcrossLabels: avgPrecisionDouble
        )
    }
}
